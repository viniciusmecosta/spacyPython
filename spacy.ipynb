{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Z-HdwN9zeMF"
      },
      "source": [
        "!pip install yake\n",
        "!pip install matplotlib\n",
        "!pip install spacy\n",
        "!pip install nltk\n",
        "!python -m spacy download pt_core_news_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8VnVULf3KX3",
        "outputId": "4a0a7a87-28fb-4c18-d35b-aa99032a7df3"
      },
      "outputs": [],
      "source": [
        "#pip install yake\n",
        "#pip install matplotlib\n",
        "#pip install spacy\n",
        "#python -m spacy download en_core_web_sm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "747l7zyI0EcJ",
        "outputId": "c28f43b5-be69-4113-cd86-12487b489e38"
      },
      "outputs": [],
      "source": [
        "#pip install spacy textblob autocorrect"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PU19bKWucaDw",
        "outputId": "fe16d3ca-a39c-49e2-8565-b0890ea8a808"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "import yake\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import spacy\n",
        "from collections import Counter\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn import metrics\n",
        "nlp = spacy.load('en_core_web_sm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "itUZlFbQcaD6"
      },
      "outputs": [],
      "source": [
        "def remove_stopwords(text):\n",
        "    doc = nlp(text)\n",
        "    tokens = [token.text.lower() for token in doc if not token.is_stop and not token.is_punct and not re.match(r'^[@¦\\x9f\\x92â\\x80]+$', token.text)]\n",
        "    filtered_text = ' '.join(tokens)\n",
        "    return filtered_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tpXFdHG5caD_"
      },
      "outputs": [],
      "source": [
        "def tokenizar(text):\n",
        "    doc = nlp(text)\n",
        "    tokens = [token.text for token in doc]\n",
        "    return tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NYVhFC_gcaEC"
      },
      "outputs": [],
      "source": [
        "def lemmatizar_tokens(tokens):\n",
        "    doc = spacy.tokens.Doc(nlp.vocab, words=tokens)\n",
        "    lemmatized_tokens = [token.lemma_ for token in nlp(doc)]\n",
        "    return lemmatized_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7FCv7ePf0Q0d"
      },
      "outputs": [],
      "source": [
        "def correct_spelling(text):\n",
        "    corrected_text = spell(text)\n",
        "    return corrected_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EiRym1At0Stw"
      },
      "outputs": [],
      "source": [
        "def correct_grammar(text):\n",
        "    blob = TextBlob(text)\n",
        "    corrected_text = str(blob.correct())\n",
        "    return corrected_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dkI72gTV0a_P"
      },
      "outputs": [],
      "source": [
        "def correct_text(text):\n",
        "    text = correct_spelling(text)\n",
        "    text = correct_grammar(text)\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qYtA_3lKD_r3"
      },
      "outputs": [],
      "source": [
        "def plot(y_test,y_pred):\n",
        "  cm = confusion_matrix(y_test,y_pred)\n",
        "  cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = cm,\n",
        "                        display_labels = [False, True])\n",
        "  cm_display.plot()\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wHkbkBcrcaEE"
      },
      "outputs": [],
      "source": [
        "def preprocess_data(data_path):\n",
        "    df = pd.read_csv(data_path)\n",
        "    df.dropna(inplace=True)\n",
        "    df['text_processed'] = df['tweet'].apply(lambda x: remove_stopwords(x))\n",
        "    df['text_tokens'] = df['text_processed'].apply(lambda x: tokenizar(x))\n",
        "    df['text_lemmatized'] = df['text_tokens'].apply(lambda x: lemmatizar_tokens(x))\n",
        "    df['text_final'] = df['text_lemmatized'].apply(lambda tokens: ' '.join(tokens))\n",
        "    return df['text_final'], df['label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bpguo4tWDb4X"
      },
      "outputs": [],
      "source": [
        "def train(X, y):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=None)\n",
        "    vectorizer = CountVectorizer()\n",
        "    X_train_vec = vectorizer.fit_transform(X_train)\n",
        "    X_test_vec = vectorizer.transform(X_test)\n",
        "    clf = MultinomialNB()\n",
        "    clf.fit(X_train_vec, y_train)\n",
        "    y_pred = clf.predict(X_test_vec)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    plot(y_test,y_pred)\n",
        "    print(\"Acurácia do modelo:\", accuracy)\n",
        "    return clf, vectorizer, accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "id": "xqFdUkZpzN_g",
        "outputId": "31ade29a-9e08-4bef-8bbd-aae56842b2a9"
      },
      "outputs": [],
      "source": [
        "X, y = preprocess_data('Twitter Sentiments.csv')\n",
        "train(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_OjFE9VucaEF"
      },
      "outputs": [],
      "source": [
        "def plot_keyword_scores(keywords):\n",
        "    keywords.sort(key=lambda x: x[1])\n",
        "    keywords_list, scores_list = zip(*keywords)\n",
        "    plt.figure(figsize=(20, 10))\n",
        "    plt.bar(keywords_list, scores_list)\n",
        "    plt.xlabel(\"Keywords\")\n",
        "    plt.ylabel(\"Scores\")\n",
        "    plt.title(\"Keyword Scores\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rwxvtJDAcaD9"
      },
      "outputs": [],
      "source": [
        "def extract_keywords(X, y, label, language='pt', n=1, k=20):\n",
        "    data_label = X[y == label]\n",
        "    data_label = ' '.join(data_label.astype(str))\n",
        "    keyword_extractor = yake.KeywordExtractor(lan=language, n=n, top=k)\n",
        "    keywords = keyword_extractor.extract_keywords(data_label)\n",
        "    keywords.sort()\n",
        "    return keywords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tQiTro1XzN_i"
      },
      "outputs": [],
      "source": [
        "keywords0 = extract_keywords(X, y, 0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "HPN_QpWWcaEG",
        "outputId": "3d6ad373-7919-4819-d221-499168f541fa"
      },
      "outputs": [],
      "source": [
        "plot_keyword_scores(keywords0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p-WlbdvqVYVT"
      },
      "outputs": [],
      "source": [
        "keywords1 = extract_keywords(X, y, 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "fjSuJcgBWdHG",
        "outputId": "f119a0c8-abd9-4c35-d3c5-0b80c2e29e68"
      },
      "outputs": [],
      "source": [
        "plot_keyword_scores(keywords1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nst2AepAOQJG",
        "outputId": "76c797f1-f7a7-43d8-b6ab-4cd7afa1be72"
      },
      "outputs": [],
      "source": [
        "docs = [nlp(texto) for texto in X[:20]]\n",
        "\n",
        "# Calcular e imprimir a similaridade entre todos os pares de textos\n",
        "for i, doc1 in enumerate(docs):\n",
        "    for j, doc2 in enumerate(docs):\n",
        "        if i != j:  # Evitar comparar um texto com ele mesmo\n",
        "            similaridade = int(doc1.similarity(doc2) * 100)\n",
        "            print(\"{} é {}% similar a {}\".format(X[i], similaridade, X[j]))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
