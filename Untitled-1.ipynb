{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import spacy\n",
    "import re\n",
    "import yake\n",
    "from textblob import TextBlob\n",
    "from autocorrect import Speller\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('pt_core_news_sm')\n",
    "spell = Speller()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    doc = nlp(text)\n",
    "    tokens = [token.text.lower() for token in doc if not token.is_stop and not token.is_punct and not re.match(r'^[@¦\\x9f\\x92â\\x80]+$', token.text)]\n",
    "    filtered_text = ' '.join(tokens)\n",
    "    return filtered_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizar(text):\n",
    "    doc = nlp(text)\n",
    "    tokens = [token.text for token in doc]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatizar_tokens(tokens):\n",
    "    doc = spacy.tokens.Doc(nlp.vocab, words=tokens)\n",
    "    lemmatized_tokens = [token.lemma_ for token in nlp(doc)]\n",
    "    return lemmatized_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_spelling(text):\n",
    "    corrected_text = spell(text)\n",
    "    return corrected_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_grammar(text):\n",
    "    blob = TextBlob(text)\n",
    "    corrected_text = str(blob.correct())\n",
    "    return corrected_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_text(text):\n",
    "    text = correct_spelling(text)\n",
    "    text = correct_grammar(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data_path):\n",
    "    df = pd.read_csv(data_path)\n",
    "    df.dropna(inplace=True)\n",
    "    df['text_processed'] = df['Texto'].apply(lambda x: remove_stopwords(x))\n",
    "    df['label'] = df['Sentimento'].map({'feliz': 0, 'nojo': 1, 'triste': 2, 'medo': 3, 'raiva': 4})\n",
    "    return df['text_processed'], df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=None)\n",
    "    vectorizer = CountVectorizer()\n",
    "    X_train_vec = vectorizer.fit_transform(X_train)\n",
    "    X_test_vec = vectorizer.transform(X_test)\n",
    "    clf = MultinomialNB()\n",
    "    clf.fit(X_train_vec, y_train)\n",
    "    y_pred = clf.predict(X_test_vec)\n",
    "    plot_confusion_matrix(y_test, y_pred)  # Chamar a função corrigida de plotagem\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Acurácia do modelo:\", accuracy)\n",
    "    return clf, vectorizer, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_confusion_matrix(y_test, y_pred):\n",
    "    labels = ['feliz', 'nojo']\n",
    "    cm = confusion_matrix(y_test, y_pred, labels=labels)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "    disp.plot(cmap=plt.cm.Blues)\n",
    "    plt.title('Matriz de Confusão')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_keyword_scores(keywords):\n",
    "    keywords.sort(key=lambda x: x[1])\n",
    "    keywords_list, scores_list = zip(*keywords)\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.bar(keywords_list, scores_list)\n",
    "    plt.xlabel(\"Palavras-chave\")\n",
    "    plt.ylabel(\"Scores\")\n",
    "    plt.title(\"Scores de Palavras-chave\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keywords(X, y, label, language='pt', n=1, k=20):\n",
    "    data_label = X[y == label]\n",
    "    data_label = ' '.join(data_label.astype(str))\n",
    "    keyword_extractor = yake.KeywordExtractor(lan=language, n=n, top=k)\n",
    "    keywords = keyword_extractor.extract_keywords(data_label)\n",
    "    keywords.sort()\n",
    "    return keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = preprocess_data('tweets_ekman.csv')\n",
    "model, vectorizer, accuracy = train(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords0 = extract_keywords(X, y, label=0)\n",
    "plot_keyword_scores(keywords0)\n",
    "\n",
    "keywords1 = extract_keywords(X, y, label=1)\n",
    "plot_keyword_scores(keywords1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
